#!/usr/bin/env python3
"""
Context Builder - Minimalistic Project Context Collector
Version: 1.0
–ü—Ä–∏–Ω—Ü–∏–ø: –ú–∏–Ω–∏–º–∞–ª–∏–∑–º, –õ–æ–∫–∞–ª—å–Ω—ã–π –ö–æ–Ω—Ç–µ–∫—Å—Ç (4.2, 4.3)

–°–±–æ—Ä—â–∏–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –ò–ò-–ø–∞—Ä—Ç–Ω–µ—Ä–∞.
–§–æ—Ä–º–∞—Ç: –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä—É–µ–º—ã–π.
"""

import ast
import fnmatch
import os
import re
from collections import defaultdict
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import List, Set, Dict, Callable, Optional, Tuple
import tempfile


# ==================== DATA STRUCTURES ====================

@dataclass
class ExclusionSet:
    """–ù–∞–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏—Å–∫–ª—é—á–µ–Ω–∏—è"""
    dirs: Set[str] = field(default_factory=lambda: {
        "__pycache__", ".git", ".svn", ".hg", ".idea", ".vscode",
        "node_modules", "venv", ".venv", "env", ".env",
        "dist", "build", "out", "target", "bin", "obj",
        ".pytest_cache", ".mypy_cache", ".ruff_cache", "coverage",
        "*.egg-info", "__pycache__", ".cache"
    })
    files: Set[str] = field(default_factory=lambda: {
        ".DS_Store", "Thumbs.db", "desktop.ini",
        "*.pyc", "*.pyo", "*.pyd", "*.so", "*.dll", "*.dylib",
        "*.class", "*.jar", "*.war", "*.ear",
        "*.log", "*.sqlite", "*.db", "*.sqlite3",
        "*.min.js", "*.min.css", "*.map",
        "package-lock.json", "yarn.lock", "pnpm-lock.yaml",
        "poetry.lock", "Pipfile.lock", "pip-delete-this-directory.txt"
    })
    file_patterns: Set[str] = field(default_factory=lambda: {
        "*.pyc", "*.log", "*.tmp", "*.temp", "*.swp", "*.swo",
        "*.bak", "*.backup", "*~", "#*#", ".#*"
    })
    extensions: Set[str] = field(default_factory=lambda: {
        ".pyc", ".pyo", ".pyd", ".so", ".dll", ".dylib",
        ".class", ".jar", ".war", ".ear", ".log",
        ".min.js", ".min.css", ".map"
    })


class FilePriority(Enum):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤"""
    CRITICAL = 100  # pyproject.toml, README.md, –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    HIGH = 80  # *.py –≤ src/, –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏
    MEDIUM = 50  # –¢–µ—Å—Ç—ã, —É—Ç–∏–ª–∏—Ç—ã, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ –∫–æ—Ä–Ω–µ
    LOW = 30  # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö, –ø—Ä–∏–º–µ—Ä—ã
    NOISE = 0  # –í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã


@dataclass
class FileAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ Python —Ñ–∞–π–ª–∞"""
    imports: List[str] = field(default_factory=list)
    classes: List[str] = field(default_factory=list)
    functions: List[str] = field(default_factory=list)
    line_count: int = 0
    code_line_count: int = 0


@dataclass
class FileInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    path: Path
    content: str
    relative_path: str
    priority: FilePriority = FilePriority.MEDIUM
    stats: Dict[str, any] = field(default_factory=dict)
    analysis: Optional[FileAnalysis] = None


# ==================== UTILITY FUNCTIONS ====================

def truncate_content(
        content: str,
        max_lines: int = 100,
        max_chars: int = 5000
) -> str:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü.

    –ï—Å–ª–∏ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π:
    - –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ max_lines/2 —Å—Ç—Ä–æ–∫
    - –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_lines/2 —Å—Ç—Ä–æ–∫
    - –ú–µ–∂–¥—É –Ω–∏–º–∏ –≤—Å—Ç–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä –æ–±—Ä–µ–∑–∫–∏
    """
    lines = content.split('\n')
    total_lines = len(lines)

    if total_lines <= max_lines and len(content) <= max_chars:
        return content

    # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å—Ç—Ä–æ–∫
    if total_lines > max_lines:
        half = max_lines // 2
        first_part = lines[:half]
        last_part = lines[-half:] if total_lines > half * 2 else []

        truncated = first_part + [f"\n[... —Ñ–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω, –ø–æ–∫–∞–∑–∞–Ω–æ {half * 2} –∏–∑ {total_lines} —Å—Ç—Ä–æ–∫ ...]\n"] + last_part
        result = '\n'.join(truncated)
    else:
        result = content

    # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤
    if len(result) > max_chars:
        result = result[:max_chars] + f"\n[... —Ñ–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω, {len(content) - max_chars} —Å–∏–º–≤–æ–ª–æ–≤ —Å–∫—Ä—ã—Ç–æ ...]"

    return result


def detect_file_priority(file_path: Path) -> FilePriority:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –ø—É—Ç–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è"""
    path_str = str(file_path)
    name = file_path.name
    parent = file_path.parent.name

    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
    if name in {"pyproject.toml", "README.md", "README.rst", "LICENSE", "MANIFEST.in"}:
        return FilePriority.CRITICAL

    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if name in {"setup.py", "setup.cfg", "requirements.txt", "Pipfile", "docker-compose.yml",
                ".env.example", ".gitignore", ".dockerignore", ".pre-commit-config.yaml"}:
        return FilePriority.HIGH

    # Python —Ñ–∞–π–ª—ã –≤ –≤–∞–∂–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
    if file_path.suffix == '.py':
        # –Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã
        if any(part in path_str for part in ['/src/', '/lib/', '/core/', '/main/', '/app/']):
            if 'test' not in name and 'test' not in path_str:
                return FilePriority.HIGH

        # –¢–µ—Å—Ç—ã
        if 'test' in name or 'tests/' in path_str or '/test_' in path_str:
            return FilePriority.MEDIUM

        # –£—Ç–∏–ª–∏—Ç—ã
        if any(part in path_str for part in ['/utils/', '/helpers/', '/tools/', '/scripts/']):
            return FilePriority.MEDIUM

    # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    if file_path.suffix in {'.md', '.rst', '.txt'}:
        if parent in {'docs', 'documentation'}:
            return FilePriority.LOW
        return FilePriority.MEDIUM

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if file_path.suffix in {'.yml', '.yaml', '.json', '.toml', '.cfg', '.ini'}:
        return FilePriority.MEDIUM

    # –û—Å—Ç–∞–ª—å–Ω–æ–µ
    return FilePriority.NOISE


def match_pattern(filename: str, pattern: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–∞–π–ª–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
    # –ü—Ä–æ—Å—Ç—ã–µ –∏–º–µ–Ω–∞
    if pattern == filename:
        return True

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å *
    if '*' in pattern:
        return fnmatch.fnmatch(filename, pattern)

    # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è
    if pattern.startswith('.'):
        return filename.endswith(pattern)

    return False


# ==================== CORE CLASSES ====================

class PythonFileAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä Python —Ñ–∞–π–ª–æ–≤"""

    def analyze(self, content: str) -> FileAnalysis:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç Python –∫–æ–¥, –∏–∑–≤–ª–µ–∫–∞—è:
        - –ò–º–ø–æ—Ä—Ç—ã (from X import Y, import Z)
        - –ö–ª–∞—Å—Å—ã (—Å –±–∞–∑–æ–≤—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏)
        - –§—É–Ω–∫—Ü–∏–∏ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ)
        - –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞
        """
        analysis = FileAnalysis()
        analysis.line_count = len(content.split('\n'))

        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                # –ò–º–ø–æ—Ä—Ç—ã
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis.imports.append(f"import {alias.name}")
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    names = ", ".join([alias.name for alias in node.names])
                    analysis.imports.append(f"from {module} import {names}")

                # –ö–ª–∞—Å—Å—ã
                elif isinstance(node, ast.ClassDef):
                    bases = []
                    for base in node.bases:
                        if isinstance(base, ast.Name):
                            bases.append(base.id)
                        elif isinstance(base, ast.Attribute):
                            bases.append(ast.unparse(base))

                    base_str = f"({', '.join(bases)})" if bases else ""
                    analysis.classes.append(f"{node.name}{base_str}")

                # –§—É–Ω–∫—Ü–∏–∏
                elif isinstance(node, ast.FunctionDef):
                    args = self._extract_function_args(node)
                    async_prefix = "async " if isinstance(node, ast.AsyncFunctionDef) else ""
                    analysis.functions.append(f"{async_prefix}{node.name}({args})")

                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
                elif isinstance(node, ast.AsyncFunctionDef):
                    args = self._extract_function_args(node)
                    analysis.functions.append(f"async {node.name}({args})")

            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞ (–∏—Å–∫–ª—é—á–∞—è –ø—É—Å—Ç—ã–µ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏)
            code_lines = [
                line for line in content.split('\n')
                if line.strip() and not line.strip().startswith('#')
            ]
            analysis.code_line_count = len(code_lines)

        except (SyntaxError, RecursionError):
            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑
            pass

        return analysis

    def _extract_function_args(self, node: ast.FunctionDef) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏"""
        args = []

        # –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        for arg in node.args.args:
            args.append(arg.arg)

        # *args
        if node.args.vararg:
            args.append(f"*{node.args.vararg.arg}")

        # **kwargs
        if node.args.kwarg:
            args.append(f"**{node.args.kwarg.arg}")

        return ", ".join(args)


class ContextBuilder:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""

    def __init__(self, root_path: str):
        self.root = Path(root_path).resolve()
        self.exclusions = ExclusionSet()
        self.custom_filters: List[Dict[str, Callable]] = []
        self.analyzer = PythonFileAnalyzer()
        self._init_default_exclusions()

    def _init_default_exclusions(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É–º–æ–ª—á–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã"""
        # –£–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ dataclass –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        pass

    def get_default_excludes(self) -> ExclusionSet:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–º–æ–ª—á–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è"""
        return self.exclusions

    def add_filter(self, name: str, condition: Callable[[Path], bool]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä"""
        self.custom_filters.append({"name": name, "condition": condition})

    def _should_exclude(self, path: Path) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –ø—É—Ç—å"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        if path.is_dir():
            if any(match_pattern(path.name, pattern) for pattern in self.exclusions.dirs):
                return True
        else:
            # –ò—Å–∫–ª—é—á–∞–µ–º –ø–æ —Ç–æ—á–Ω–æ–º—É –∏–º–µ–Ω–∏
            if any(match_pattern(path.name, pattern) for pattern in self.exclusions.files):
                return True

            # –ò—Å–∫–ª—é—á–∞–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
            if any(fnmatch.fnmatch(path.name, pattern) for pattern in self.exclusions.file_patterns):
                return True

            # –ò—Å–∫–ª—é—á–∞–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
            if any(path.suffix == ext for ext in self.exclusions.extensions):
                return True

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        for filter_info in self.custom_filters:
            if filter_info["condition"](path):
                return True

        return False

    def apply_filters(self, files: List[Path]) -> List[Path]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –∫ —Å–ø–∏—Å–∫—É —Ñ–∞–π–ª–æ–≤"""
        return [f for f in files if not self._should_exclude(f)]

    def _collect_all_files(self) -> List[Path]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ"""
        all_files = []

        for root_dir, dirs, files in os.walk(self.root, topdown=True):
            root_path = Path(root_dir)

            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [d for d in dirs if not self._should_exclude(root_path / d)]

            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã
            for file in files:
                file_path = root_path / file
                if not self._should_exclude(file_path):
                    all_files.append(file_path)

        return all_files

    def build_directory_tree(self) -> str:
        """
        –°—Ç—Ä–æ–∏—Ç –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –¥–µ—Ä–µ–≤–æ –ø–∞–ø–æ–∫

        –§–æ—Ä–º–∞—Ç:
        project/
        ‚îú‚îÄ‚îÄ src/
        ‚îÇ   ‚îî‚îÄ‚îÄ core/
        ‚îÇ       ‚îî‚îÄ‚îÄ node.py
        ‚îî‚îÄ‚îÄ tests/
            ‚îî‚îÄ‚îÄ test_node.py
        """
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        structure = defaultdict(list)

        for file_path in self._collect_all_files():
            relative = file_path.relative_to(self.root)
            parts = relative.parts

            if len(parts) == 1:
                structure['.'].append(parts[0])
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                for i in range(1, len(parts)):
                    dir_path = '/'.join(parts[:i])
                    if i == len(parts) - 1:
                        # –§–∞–π–ª
                        structure[dir_path].append(parts[i])
                    else:
                        # –ü–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (–¥–æ–±–∞–≤–∏–º, –µ—Å–ª–∏ –µ—â–µ –Ω–µ—Ç)
                        dir_name = parts[i]
                        if dir_name not in structure[dir_path]:
                            structure[dir_path].append(dir_name)

        # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ
        lines = []

        def build_tree(node: str, prefix: str = "", is_last: bool = True):
            children = sorted(structure.get(node, []))

            for i, child in enumerate(children):
                child_is_last = i == len(children) - 1
                child_prefix = prefix + ("    " if is_last else "‚îÇ   ")

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∏–ª–∏ —Ñ–∞–π–ª)
                child_path = f"{node}/{child}" if node != '.' else child
                is_dir = child_path in structure or '/' in child

                icon = "üìÅ " if is_dir else "üìÑ "
                if node == '.':
                    lines.append(f"{icon}{child}")
                else:
                    lines.append(f"{prefix}{'‚îî‚îÄ‚îÄ ' if is_last else '‚îú‚îÄ‚îÄ '}{icon}{child}")

                if is_dir:
                    build_tree(child_path, child_prefix, child_is_last)

        # –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–æ—Ä–Ω—è
        if '.' in structure:
            for child in sorted(structure['.']):
                child_path = child
                is_dir = child_path in structure or '/' in child_path

                icon = "üìÅ " if is_dir else "üìÑ "
                lines.append(f"{icon}{child}")

                if is_dir:
                    build_tree(child_path, "", False)

        return "\n".join(lines)

    def prioritize_files(self, file_paths: List[str]) -> List[str]:
        """–°–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–≤–∞–∂–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏)"""
        files_with_priority = []

        for file_str in file_paths:
            file_path = Path(file_str)
            priority = detect_file_priority(file_path)
            files_with_priority.append((priority.value, file_str))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (—É–±—ã–≤–∞–Ω–∏–µ), –∑–∞—Ç–µ–º –ø–æ –∏–º–µ–Ω–∏
        files_with_priority.sort(key=lambda x: (-x[0], x[1]))

        return [file_str for _, file_str in files_with_priority]

    def _read_file(self, file_path: Path) -> Optional[str]:
        """–ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except (IOError, OSError, UnicodeDecodeError):
            return None

    def format_file_entry(self, file_info: FileInfo) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å—å –æ —Ñ–∞–π–ª–µ

        –§–æ—Ä–º–∞—Ç:
        src/core/node.py
        ‚ï∞‚îÄ 3 –∏–º–ø–æ—Ä—Ç–∞, 2 –∫–ª–∞—Å—Å–∞, 5 —Ñ—É–Ω–∫—Ü–∏–π
           class Node:
               def method(self):
                   pass
        """
        lines = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –ø—É—Ç–µ–º
        lines.append(f"üìÑ {file_info.relative_path}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats_parts = []
        if file_info.analysis:
            if file_info.analysis.imports:
                count = len(file_info.analysis.imports)
                stats_parts.append(f"{count} –∏–º–ø–æ—Ä—Ç{'–æ–≤' if count % 10 > 1 else ''}")
            if file_info.analysis.classes:
                count = len(file_info.analysis.classes)
                stats_parts.append(f"{count} –∫–ª–∞—Å—Å{'–æ–≤' if count % 10 > 1 else ''}")
            if file_info.analysis.functions:
                count = len(file_info.analysis.functions)
                stats_parts.append(f"{count} —Ñ—É–Ω–∫—Ü–∏{'–π' if count % 10 > 1 else '—è'}")
            if file_info.analysis.line_count:
                stats_parts.append(f"{file_info.analysis.line_count} —Å—Ç—Ä–æ–∫")

        if stats_parts:
            lines.append(f"‚ï∞‚îÄ {', '.join(stats_parts)}")

        # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ
        if file_info.content.strip():
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            content_lines = file_info.content.split('\n')
            for i, line in enumerate(content_lines):
                if i == 0:
                    lines.append(f"   {line}")
                else:
                    lines.append(f"   {line}")

        return '\n'.join(lines)

    def build(self) -> str:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç

        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã–≤–æ–¥–∞:
        ========== –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û–ï–ö–¢–ê ==========

        [–î–ï–†–ï–í–û –ü–†–û–ï–ö–¢–ê]

        ========== –°–û–î–ï–†–ñ–ê–ù–ò–ï ==========

        [–§–ê–ô–õ 1]
        [—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ]

        [–§–ê–ô–õ 2]
        [—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ]

        ========== –î–õ–Ø –ò–ò ==========
        [–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏]
        """
        parts = []

        # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫
        parts.append("=" * 40)
        parts.append(f"–ö–û–ù–¢–ï–ö–°–¢ –ü–†–û–ï–ö–¢–ê: {self.root.name}")
        parts.append(f"–°–æ–±—Ä–∞–Ω–æ: {self.__class__.__name__}")
        parts.append("=" * 40)

        # 2. –î–µ—Ä–µ–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        parts.append("\nüå≥ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:\n")
        try:
            tree = self.build_directory_tree()
            parts.append(tree)
        except Exception as e:
            parts.append(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –¥–µ—Ä–µ–≤–æ: {e}")

        # 3. –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        parts.append("\n" + "=" * 40)
        parts.append("üìÅ –°–û–î–ï–†–ñ–ê–ù–ò–ï –§–ê–ô–õ–û–í:")
        parts.append("=" * 40 + "\n")

        # –°–æ–±–∏—Ä–∞–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        all_files = self._collect_all_files()
        if not all_files:
            parts.append("‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        else:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            file_strings = [str(f.relative_to(self.root)) for f in all_files]
            prioritized = self.prioritize_files(file_strings)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            max_files = 50
            if len(prioritized) > max_files:
                parts.append(f"üìä –ü–æ–∫–∞–∑–∞–Ω–æ {max_files} –∏–∑ {len(prioritized)} —Ñ–∞–π–ª–æ–≤ (–æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∫—Ä—ã—Ç—ã)\n")
                prioritized = prioritized[:max_files]

            # –ß–∏—Ç–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
            for i, file_str in enumerate(prioritized, 1):
                file_path = self.root / file_str
                content = self._read_file(file_path)

                if content:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º Python —Ñ–∞–π–ª—ã
                    analysis = None
                    if file_path.suffix == '.py':
                        analysis = self.analyzer.analyze(content)

                    # –û–±—Ä–µ–∑–∞–µ–º –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã
                    truncated = truncate_content(content, max_lines=100, max_chars=5000)

                    file_info = FileInfo(
                        path=file_path,
                        content=truncated,
                        relative_path=file_str,
                        priority=detect_file_priority(file_path),
                        analysis=analysis
                    )

                    formatted = self.format_file_entry(file_info)
                    parts.append(formatted)

                    # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
                    if i < len(prioritized):
                        parts.append("\n" + "-" * 40 + "\n")

        # 4. –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ò–ò
        parts.append("\n" + "=" * 40)
        parts.append("ü§ñ –ö–û–ù–¢–ï–ö–°–¢ –î–õ–Ø –ò–ò:")
        parts.append("=" * 40)
        parts.append("""
–¢—ã –≤–∏–¥–∏—à—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø—Ä–æ–µ–∫—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è:
1. –ü–æ–Ω–∏–º–∞–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
2. –ê–Ω–∞–ª–∏–∑–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–¥–∞
3. –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å –ø—Ä–æ–µ–∫—Ç–æ–º

–û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞:
‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ (–¥–µ—Ä–µ–≤–æ –≤–≤–µ—Ä—Ö—É)
‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã (–∏–¥—É—Ç –ø–µ—Ä–≤—ã–º–∏)
‚Ä¢ –ê–Ω–∞–ª–∏–∑ Python —Ñ–∞–π–ª–æ–≤ (–∏–º–ø–æ—Ä—Ç—ã, –∫–ª–∞—Å—Å—ã, —Ñ—É–Ω–∫—Ü–∏–∏)

–ü—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞:
1. –°–ª–µ–¥—É–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
2. –ò—Å–ø–æ–ª—å–∑—É–π —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥—É–ª–∏
3. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π —Å—Ç–∏–ª—å –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞
4. –£—á–∏—Ç—ã–≤–∞–π –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞

–§–∞–π–ª—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏. –ù–∞—á–Ω–∏ —Å –ø–µ—Ä–≤—ã—Ö.
""")

        return "\n".join(parts)


# ==================== MAIN & CLI ====================

def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ CLI"""
    import argparse

    parser = argparse.ArgumentParser(
        description="–°–±–æ—Ä—â–∏–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –ò–ò (–º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  %(prog)s                         # –°–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
  %(prog)s -p /path/to/project     # –°–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
  %(prog)s -o context.txt          # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ñ–∞–π–ª
  %(prog)s -v                      # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        """
    )

    parser.add_argument(
        "path",
        nargs="?",
        default=".",
        help="–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)"
    )

    parser.add_argument(
        "-o", "--output",
        help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª"
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )

    parser.add_argument(
        "--add-exclude",
        action="append",
        default=[],
        help="–î–æ–±–∞–≤–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ (–ø–∞—Ç—Ç–µ—Ä–Ω)"
    )

    parser.add_argument(
        "--no-truncate",
        action="store_true",
        help="–ù–µ –æ–±—Ä–µ–∑–∞—Ç—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã"
    )

    args = parser.parse_args()

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–±–æ—Ä—â–∏–∫
        builder = ContextBuilder(args.path)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        for pattern in args.add_exclude:
            builder.add_filter(f"custom_{pattern}", lambda p, pat=pattern: fnmatch.fnmatch(p.name, pat))

        if args.verbose:
            print(f"üîç –°–∫–∞–Ω–∏—Ä—É—é –ø—Ä–æ–µ–∫—Ç: {builder.root}")
            excludes = builder.get_default_excludes()
            print(f"üìã –ò—Å–∫–ª—é—á–µ–Ω–∏—è: {len(excludes.dirs)} –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, {len(excludes.files)} —Ñ–∞–π–ª–æ–≤")

        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = builder.build()

        # –í—ã–≤–æ–¥–∏–º –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(context)
            print(f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {args.output}")
            print(f"üìè –†–∞–∑–º–µ—Ä: {len(context):,} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            print(context)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())